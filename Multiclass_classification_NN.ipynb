{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b4d6f75-a4d1-49d3-899f-a5b8e59ccb6b",
      "metadata": {
        "id": "1b4d6f75-a4d1-49d3-899f-a5b8e59ccb6b"
      },
      "source": [
        "# <font color = 'orange'>**MultiClass Classification using Mini Batch Gradient Descent with PyTorch**</font>\n",
        "\n",
        "In this project, I’m building a multiclass classification model using PyTorch and **Mini-Batch Gradient Descent**.\n",
        "\n",
        "- **Data Generation**: I’m generating a synthetic dataset using `make_classification` with:\n",
        "  - **1000 samples**, each with **5 features**.\n",
        "  - **3 classes** for classification.\n",
        "  - **4 informative features** and **1 redundant feature** (redundant means it can be derived from the other features).\n",
        "  - **random_state=0** to keep things reproducible.\n",
        "\n",
        "- **Custom Dataset Class**: I’ll convert the data into PyTorch tensors and create a custom dataset class to handle mini-batch loading efficiently.\n",
        "\n",
        "- **Mini-Batch Gradient Descent**: Here’s the five-step training process I’ll use:\n",
        "  1. **Initialize weights** randomly.\n",
        "  2. **Forward pass**: Get predictions for each mini-batch.\n",
        "  3. **Compute loss** for the mini-batch.\n",
        "  4. **Backpropagate** to calculate gradients.\n",
        "  5. **Update weights** based on the gradients from each mini-batch.\n",
        "\n",
        "- **Training Loop**: I’ll repeat this over multiple epochs. Each epoch will process the dataset in mini-batches, updating the weights after every batch.\n",
        "\n",
        "- **Hyperparameters**: I’ll fine-tune the learning rate, mini-batch size, and number of epochs based on performance during training.\n",
        "\n",
        "Lastly, I’ll write functions for steps 1 to 4 to streamline the training process using **Mini-Batch Gradient Descent**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce0e622a-d0f7-4f88-a7b6-6ef761a76ed9",
      "metadata": {
        "id": "ce0e622a-d0f7-4f88-a7b6-6ef761a76ed9"
      },
      "outputs": [],
      "source": [
        "# importing the make_classification function from the sklearn.datasets module used to generate synthetic data\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# importing the Standard Scaler for standardizing features by removing the mean and scaling to unit variance.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Importing the main torch library for constructing Neural Networks\n",
        "import torch\n",
        "\n",
        "# Import the torch.nn module which contains pre-defined layers, loss functions etc for Neural Networks\n",
        "import torch.nn as nn\n",
        "\n",
        "# Importing the torch.optim module from torch which contains various optimization algorithms like SGD, Adam, etc\n",
        "import torch.optim as optim\n",
        "\n",
        "# Importing the torch.functional moducle from PyTorch which contains functional forms of layers, loss function and other operations\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import the DataLoader and Dataset classes from pytorch utils; Dataloader helps use with batching, shuffling and loading data in parallel.\n",
        "# Dataset provides an abstract interface for easier data maniupulation and handling.\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03603153",
      "metadata": {
        "id": "03603153"
      },
      "outputs": [],
      "source": [
        "# Generate a synthetic dataset for classification using make_classification function.\n",
        "# Parameters:\n",
        "# - n_samples=1000: The total number of samples in the generated dataset.\n",
        "# - n_features=5: The total number of features for each sample.\n",
        "# - n_classes=3: The number of classes for the classification task.\n",
        "# - n_informative=4: The number of informative features, i.e., features that are actually useful for classification.\n",
        "# - n_redundant=1: The number of redundant features, i.e., features that can be linearly derived from informative features.\n",
        "# - random_state=0: The seed for the random number generator to ensure reproducibility.\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=5, n_classes=3, n_informative=4, n_redundant=1, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "251c9161",
      "metadata": {
        "id": "251c9161"
      },
      "outputs": [],
      "source": [
        "# initilializing the preprocessor for the feature scaling\n",
        "preprocessor = StandardScaler()\n",
        "\n",
        "X = preprocessor.fit_transform(X) # Running both the fit and transform on the dataset for the features before splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "731fb4ee",
      "metadata": {
        "id": "731fb4ee",
        "outputId": "39cbdf86-7e83-450a-cc2d-5abae008f9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 5) (1000,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba5486c",
      "metadata": {
        "id": "0ba5486c",
        "outputId": "42062f2c-bc16-4e06-e80a-6998f60f452c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.39443436, -0.78033571, -0.25005511,  0.09118536, -0.5690698 ],\n",
              "       [ 0.64284479, -0.95837057,  0.83598996, -0.08438568,  0.50539358],\n",
              "       [ 0.99102498,  0.8580679 ,  0.78786062, -0.9114329 ,  1.62615938],\n",
              "       [-0.96923966,  0.86168226, -1.31837608, -1.22844863, -0.07591589],\n",
              "       [ 0.96021518,  0.99206623,  1.0026402 , -0.25339161,  1.18831784]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9359465",
      "metadata": {
        "id": "f9359465",
        "outputId": "80e744df-0f30-4fdd-ec6c-f20d8402731a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 0, 1, 2, 1, 1, 0, 2, 0, 0])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f49ae22",
      "metadata": {
        "id": "6f49ae22"
      },
      "source": [
        "### <font color = 'orange'>**Input and True Label Observations**\n",
        "- <font color = 'orange'>**Inputs:**</font> Every row represents one sample in X and the randomized feature values for that sample.\n",
        "- <font color = 'orange'>**True Labels:**</font> We have a one row matrix with 1000 labels 0, 1, or 2 based on the indicated class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f349675",
      "metadata": {
        "id": "9f349675"
      },
      "outputs": [],
      "source": [
        "# Convert numpy arrays X and y to PyTorch Tensors for multiclass classification.\n",
        "# X is converted to a float tensor, and y is converted to a long integer tensor as required for CrossEntropyLoss.\n",
        "\n",
        "x_tensor = torch.tensor(X, dtype=torch.float, requires_grad=True)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)  # y needs to be long for CrossEntropyLoss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac97bd3b",
      "metadata": {
        "id": "ac97bd3b"
      },
      "source": [
        "## <font color='orange'>**Custom PyTorch Dataset Class**</font>\n",
        "\n",
        "In this part of the project, I’m creating a custom `Dataset` class to handle my training data efficiently. The class is designed to work with PyTorch’s DataLoader, which helps manage mini-batch loading during training.\n",
        "\n",
        "- **`__init__`**: This is the constructor that initializes the dataset with the input features (`X`) and the labels (`y`). This allows me to easily pass the numpy arrays or tensors into the dataset object.\n",
        "  \n",
        "- **`__len__`**: This method returns the total number of samples in the dataset, which is simply the number of labels. PyTorch uses this to know how many data points exist when batching.\n",
        "  \n",
        "- **`__getitem__`**: This method is used to retrieve a specific sample (feature-label pair) by its index. It’s how PyTorch’s DataLoader will access individual data points when building batches during training.\n",
        "\n",
        "By building this custom class, I can make sure that my data is easily accessible and ready for PyTorch’s training loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343ce2ee",
      "metadata": {
        "id": "343ce2ee"
      },
      "outputs": [],
      "source": [
        "# Definining a custom PyTorch DataSet class for handling my data\n",
        "class MyDataset(Dataset):\n",
        "    # Constructor: inititializes the dataset with features and labels\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    # Method to return length of the dataset\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0] # pulls the shape value of the 1st index\n",
        "\n",
        "    # Method to get a data point by the index\n",
        "    def __getitem__(self, index):\n",
        "        x = self.features[index]\n",
        "        y = self.labels[index]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b017e5cb",
      "metadata": {
        "id": "b017e5cb"
      },
      "source": [
        "## <font color='orange'>**Creating a Dataset Instance**</font>\n",
        "\n",
        "Here, I’m creating an instance of my custom `MyDataset` class by passing in the feature (`x_tensor`) and label (`y_tensor`) tensors. This prepares my data to be used by PyTorch’s DataLoader for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fc24268",
      "metadata": {
        "id": "6fc24268"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(X=x_tensor, y = y_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1618e667",
      "metadata": {
        "id": "1618e667",
        "outputId": "d510defb-2b63-433d-c56c-f0d27a9fda3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-0.3944, -0.7803, -0.2501,  0.0912, -0.5691],\n",
              "        grad_fn=<SelectBackward0>),\n",
              " tensor(2))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Accessing the first element (feature - label pair from the train_dataset using indexing)\n",
        "# The __getitem__method of the MyDataset class is called to return the element.\n",
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0efd6c29",
      "metadata": {
        "id": "0efd6c29"
      },
      "source": [
        "- <font color = 'orange'>**Above we can see the element with the five feature values and the class label of 2**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1348ad1f",
      "metadata": {
        "id": "1348ad1f"
      },
      "source": [
        "## <font color='orange'>**Creating a DataLoader**</font>\n",
        "\n",
        "Now, I’m creating a `DataLoader` from my dataset, with a batch size of 16 and `shuffle=True` to randomize the order of samples during training. This helps in efficiently loading data in mini-batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9786488c",
      "metadata": {
        "id": "9786488c"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "711e0de3",
      "metadata": {
        "id": "711e0de3"
      },
      "source": [
        "## <font color='orange'>**Defining the Model**</font>\n",
        "\n",
        "This model takes a 5-dimensional input and outputs 3 dimensions, which matches the number of classes in my classification task. The `bias=True` means that bias terms will be added during the transformation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6526b838",
      "metadata": {
        "id": "6526b838"
      },
      "outputs": [],
      "source": [
        "model = nn.Linear(in_features = 5 , out_features =3, bias = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc883947",
      "metadata": {
        "id": "bc883947"
      },
      "source": [
        "## <font color='orange'>**Using CrossEntropy Loss**</font>\n",
        "\n",
        "I’m using PyTorch’s built-in `CrossEntropyLoss`, which combines the softmax function with cross-entropy in one step. This means I don’t need to apply softmax separately.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797557b2",
      "metadata": {
        "id": "797557b2"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e67e31",
      "metadata": {
        "id": "97e67e31"
      },
      "source": [
        "## <font color='orange'>**Custom Weight Initialization**</font>\n",
        "\n",
        "This function initializes the weights and biases for `nn.Linear` layers. The weights are initialized with a normal distribution (mean=0, std=0.05), and the bias terms are set to zero. It ensures that each linear layer starts with a specific, controlled initialization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b91eec03",
      "metadata": {
        "id": "b91eec03"
      },
      "outputs": [],
      "source": [
        "def init_weights(layer):\n",
        "    # Checking to see if the layer is of type nn.Linear\n",
        "    if type(layer) == nn.Linear:\n",
        "        # initialize the weights with a normal distribution, centered at 0 with a standard dev of 0.05\n",
        "        torch.nn.init.normal_(layer.weight, mean = 0, std = 0.05)\n",
        "        # initializing the bias terms to zero\n",
        "        torch.nn.init.zeros_(layer.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c3a01e4",
      "metadata": {
        "id": "1c3a01e4"
      },
      "source": [
        "## <font color='orange'>**Training Function**</font>\n",
        "\n",
        "This function trains the neural network over a specified number of epochs using the provided model, loss function, and optimizer.\n",
        "\n",
        "1. **Loop through epochs**: The training process repeats for the number of epochs defined.\n",
        "2. **Loop through batches**: For each batch in the dataset:\n",
        "    - Move the input and target tensors to the appropriate device (CPU/GPU).\n",
        "    - Perform the forward pass to get predictions from the model.\n",
        "    - Compute the loss based on the model's predictions and actual targets.\n",
        "3. **Backpropagation**:\n",
        "    - Zero the gradients, compute new gradients, and update the model parameters using the optimizer.\n",
        "4. **Track performance**:\n",
        "    - Calculate running loss and correct predictions for each batch.\n",
        "    - Compute average loss and accuracy over the entire dataset for the epoch.\n",
        "5. **Display metrics**: Print out the loss and accuracy for each epoch to monitor training progress.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78a57a37",
      "metadata": {
        "id": "78a57a37"
      },
      "outputs": [],
      "source": [
        "# Function to train a neural network model.\n",
        "# Arguments include epochs, loss_function, learning_rate, model_architechture, and optimizer\n",
        "\n",
        "def train(epochs, loss_function, learning_rate, model, optimizer):\n",
        "\n",
        "    # Loop for each training cycle\n",
        "    for epoch in range(epochs):\n",
        "        # initializing variables to store the training loss and correct prediction count for each epoch\n",
        "        running_train_loss = 0\n",
        "        running_train_correct = 0\n",
        "        # looping through every batch in training dataset using the train_loader\n",
        "        for x, y in train_loader:\n",
        "            # moving the input and target tensors to the device\n",
        "            x = x.to(device)\n",
        "\n",
        "            targets = y.to(device)\n",
        "\n",
        "            # Calculating the forward pass\n",
        "            output = model(x)\n",
        "\n",
        "            # Calculating the loss\n",
        "            loss = loss_function(output, targets)\n",
        "\n",
        "            # Zero out the gradients from the previous iteration\n",
        "            optimizer.zero_grad()\n",
        "            # Backward pass to compute the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # updating the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulating the loss for the batch\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "            # Evaluating the performance with backpropogation\n",
        "            with torch.no_grad():\n",
        "                y_pred = torch.argmax(output, dim = 1) # pulls the predictions based on the maximum class probability after passing through softmax.\n",
        "                correct = (y_pred == targets).sum().item() #calclates the sum of the items where y_pred == targets accumulating the correct predictions for this batch\n",
        "                running_train_correct += correct # accumulates the number of correct predictions\n",
        "\n",
        "\n",
        "            train_loss = running_train_loss/len(train_loader) # Computing the average training loss for each epoch by taking each batch and averaging for that epoch\n",
        "            train_accuracy = running_train_correct / len(train_loader.dataset) # calculating the accuracy accross the whole dataset, in this example we would be dividing by 1000\n",
        "\n",
        "            # Displaying the training loss and accuracy for the current epoch\n",
        "            print(f'Epoch : {epoch + 1} / {epochs}')\n",
        "            print(f'Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy * 100:.4f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183f834c",
      "metadata": {
        "id": "183f834c"
      },
      "source": [
        "## <font color='orange'>**Setting Up and Training the Model**</font>\n",
        "\n",
        "1. **Random Seed**: Fixes the random seed for reproducibility.\n",
        "2. **Epochs**: Sets the number of training epochs to 5.\n",
        "3. **Device Configuration**: Detects if a GPU is available and uses it; otherwise defaults to CPU.\n",
        "4. **Learning Rate**: Sets the learning rate to 1.\n",
        "5. **Optimizer**: Configures the optimizer as SGD using the model’s parameters and the defined learning rate.\n",
        "6. **Model to Device**: Moves the model to the appropriate device (CPU or GPU).\n",
        "7. **Custom Weight Initialization**: Applies a custom weight initialization function across all layers of the model.\n",
        "8. **Training Process**: Starts the training process with the specified epochs, loss function, model, and optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a23dbaf",
      "metadata": {
        "id": "9a23dbaf",
        "outputId": "26a08f01-e56e-4a4e-9340-1f665aac792e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.0171 | Train Accuracy: 0.8000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.0340 | Train Accuracy: 1.4000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.0516 | Train Accuracy: 2.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.0647 | Train Accuracy: 3.4000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.0784 | Train Accuracy: 4.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.0915 | Train Accuracy: 5.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1047 | Train Accuracy: 6.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1179 | Train Accuracy: 7.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1336 | Train Accuracy: 7.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1438 | Train Accuracy: 9.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1515 | Train Accuracy: 10.6000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1642 | Train Accuracy: 11.7000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1767 | Train Accuracy: 12.7000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.1896 | Train Accuracy: 13.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2069 | Train Accuracy: 14.6000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2194 | Train Accuracy: 15.8000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2293 | Train Accuracy: 17.0000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2372 | Train Accuracy: 18.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2449 | Train Accuracy: 19.6000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2584 | Train Accuracy: 20.7000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2666 | Train Accuracy: 22.0000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2798 | Train Accuracy: 23.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.2990 | Train Accuracy: 24.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3105 | Train Accuracy: 25.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3266 | Train Accuracy: 26.1000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3364 | Train Accuracy: 27.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3446 | Train Accuracy: 28.5000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3555 | Train Accuracy: 29.5000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3684 | Train Accuracy: 30.4000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3789 | Train Accuracy: 31.7000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.3904 | Train Accuracy: 32.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.4035 | Train Accuracy: 34.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.4121 | Train Accuracy: 35.4000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.4268 | Train Accuracy: 36.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.4371 | Train Accuracy: 37.4000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.4499 | Train Accuracy: 38.5000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.4567 | Train Accuracy: 39.7000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.4754 | Train Accuracy: 40.6000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.5000 | Train Accuracy: 41.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.5151 | Train Accuracy: 42.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.5270 | Train Accuracy: 43.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.5433 | Train Accuracy: 44.1000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.5568 | Train Accuracy: 45.1000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.5725 | Train Accuracy: 45.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.5891 | Train Accuracy: 46.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6034 | Train Accuracy: 47.8000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6191 | Train Accuracy: 48.8000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6332 | Train Accuracy: 49.6000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6429 | Train Accuracy: 50.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6533 | Train Accuracy: 52.0000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6652 | Train Accuracy: 53.0000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6744 | Train Accuracy: 54.2000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.6877 | Train Accuracy: 55.1000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7000 | Train Accuracy: 56.4000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7127 | Train Accuracy: 57.3000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7264 | Train Accuracy: 58.4000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7324 | Train Accuracy: 59.8000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7420 | Train Accuracy: 60.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7582 | Train Accuracy: 62.0000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7710 | Train Accuracy: 63.0000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.7901 | Train Accuracy: 63.7000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.8030 | Train Accuracy: 64.9000%\n",
            "Epoch : 1 / 5\n",
            "Train Loss: 0.8130 | Train Accuracy: 65.4000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.0139 | Train Accuracy: 1.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.0291 | Train Accuracy: 1.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.0421 | Train Accuracy: 2.7000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.0572 | Train Accuracy: 3.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.0688 | Train Accuracy: 5.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.0866 | Train Accuracy: 5.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.0971 | Train Accuracy: 7.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1102 | Train Accuracy: 7.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1213 | Train Accuracy: 9.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1366 | Train Accuracy: 10.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1469 | Train Accuracy: 11.6000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1545 | Train Accuracy: 13.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1632 | Train Accuracy: 14.3000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1729 | Train Accuracy: 15.6000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1873 | Train Accuracy: 16.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.1989 | Train Accuracy: 17.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.2092 | Train Accuracy: 18.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.2188 | Train Accuracy: 19.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.2307 | Train Accuracy: 21.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.2436 | Train Accuracy: 22.4000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.2558 | Train Accuracy: 23.6000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.2740 | Train Accuracy: 24.7000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.2852 | Train Accuracy: 26.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.3001 | Train Accuracy: 26.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.3139 | Train Accuracy: 27.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.3319 | Train Accuracy: 28.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.3457 | Train Accuracy: 29.7000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.3580 | Train Accuracy: 30.7000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.3710 | Train Accuracy: 31.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.3854 | Train Accuracy: 33.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4017 | Train Accuracy: 33.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4140 | Train Accuracy: 34.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4255 | Train Accuracy: 36.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4434 | Train Accuracy: 36.5000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4508 | Train Accuracy: 37.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4610 | Train Accuracy: 39.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4791 | Train Accuracy: 40.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.4890 | Train Accuracy: 41.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5089 | Train Accuracy: 42.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5220 | Train Accuracy: 43.4000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5296 | Train Accuracy: 44.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5416 | Train Accuracy: 45.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5522 | Train Accuracy: 47.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5622 | Train Accuracy: 48.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5775 | Train Accuracy: 49.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5870 | Train Accuracy: 50.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.5964 | Train Accuracy: 51.3000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.6166 | Train Accuracy: 51.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.6258 | Train Accuracy: 53.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.6357 | Train Accuracy: 54.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.6491 | Train Accuracy: 55.3000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.6624 | Train Accuracy: 56.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.6771 | Train Accuracy: 57.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.6956 | Train Accuracy: 57.8000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7060 | Train Accuracy: 58.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7162 | Train Accuracy: 59.9000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7270 | Train Accuracy: 61.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7395 | Train Accuracy: 62.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7509 | Train Accuracy: 63.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7676 | Train Accuracy: 64.2000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7802 | Train Accuracy: 65.1000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.7934 | Train Accuracy: 66.0000%\n",
            "Epoch : 2 / 5\n",
            "Train Loss: 0.8005 | Train Accuracy: 66.7000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.0241 | Train Accuracy: 0.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.0316 | Train Accuracy: 1.9000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.0474 | Train Accuracy: 2.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.0611 | Train Accuracy: 4.1000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.0699 | Train Accuracy: 5.4000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.0874 | Train Accuracy: 6.3000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.0972 | Train Accuracy: 7.5000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.1110 | Train Accuracy: 8.5000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.1265 | Train Accuracy: 9.4000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.1420 | Train Accuracy: 10.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.1515 | Train Accuracy: 11.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.1662 | Train Accuracy: 12.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.1780 | Train Accuracy: 13.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.1951 | Train Accuracy: 14.7000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2080 | Train Accuracy: 15.5000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2178 | Train Accuracy: 17.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2289 | Train Accuracy: 18.2000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2364 | Train Accuracy: 19.5000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2458 | Train Accuracy: 20.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2552 | Train Accuracy: 21.9000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2690 | Train Accuracy: 22.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2800 | Train Accuracy: 24.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2888 | Train Accuracy: 25.2000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.2992 | Train Accuracy: 26.4000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.3064 | Train Accuracy: 27.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.3192 | Train Accuracy: 28.7000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.3316 | Train Accuracy: 29.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.3520 | Train Accuracy: 30.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.3655 | Train Accuracy: 31.7000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.3772 | Train Accuracy: 32.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.3902 | Train Accuracy: 34.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4034 | Train Accuracy: 34.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4163 | Train Accuracy: 35.7000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4230 | Train Accuracy: 37.1000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4349 | Train Accuracy: 38.1000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4504 | Train Accuracy: 39.2000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4601 | Train Accuracy: 40.5000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4759 | Train Accuracy: 41.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4882 | Train Accuracy: 42.7000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.4972 | Train Accuracy: 44.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.5139 | Train Accuracy: 45.1000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.5323 | Train Accuracy: 45.9000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.5454 | Train Accuracy: 47.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.5581 | Train Accuracy: 48.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.5656 | Train Accuracy: 49.2000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.5824 | Train Accuracy: 50.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.5949 | Train Accuracy: 51.1000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.6039 | Train Accuracy: 52.2000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.6167 | Train Accuracy: 53.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.6291 | Train Accuracy: 54.0000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.6465 | Train Accuracy: 54.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.6668 | Train Accuracy: 55.5000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.6793 | Train Accuracy: 56.4000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.6917 | Train Accuracy: 57.4000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7051 | Train Accuracy: 58.4000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7239 | Train Accuracy: 59.1000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7341 | Train Accuracy: 60.3000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7474 | Train Accuracy: 61.3000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7577 | Train Accuracy: 62.6000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7658 | Train Accuracy: 63.8000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7723 | Train Accuracy: 65.2000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7811 | Train Accuracy: 66.4000%\n",
            "Epoch : 3 / 5\n",
            "Train Loss: 0.7915 | Train Accuracy: 67.0000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.0199 | Train Accuracy: 1.1000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.0372 | Train Accuracy: 2.1000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.0459 | Train Accuracy: 3.4000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.0632 | Train Accuracy: 4.3000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.0755 | Train Accuracy: 5.2000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.0843 | Train Accuracy: 6.4000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.0951 | Train Accuracy: 7.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1071 | Train Accuracy: 8.9000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1226 | Train Accuracy: 9.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1311 | Train Accuracy: 11.1000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1457 | Train Accuracy: 12.1000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1537 | Train Accuracy: 13.3000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1650 | Train Accuracy: 14.4000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1742 | Train Accuracy: 15.5000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.1866 | Train Accuracy: 16.5000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2046 | Train Accuracy: 17.2000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2125 | Train Accuracy: 18.5000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2184 | Train Accuracy: 19.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2343 | Train Accuracy: 20.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2490 | Train Accuracy: 21.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2600 | Train Accuracy: 22.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2735 | Train Accuracy: 23.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.2920 | Train Accuracy: 24.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3062 | Train Accuracy: 25.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3180 | Train Accuracy: 26.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3344 | Train Accuracy: 27.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3432 | Train Accuracy: 28.9000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3498 | Train Accuracy: 30.3000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3601 | Train Accuracy: 31.5000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3695 | Train Accuracy: 32.9000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.3860 | Train Accuracy: 33.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4000 | Train Accuracy: 34.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4163 | Train Accuracy: 35.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4301 | Train Accuracy: 36.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4416 | Train Accuracy: 37.9000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4496 | Train Accuracy: 39.2000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4580 | Train Accuracy: 40.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4674 | Train Accuracy: 41.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4769 | Train Accuracy: 42.9000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.4955 | Train Accuracy: 43.9000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.5050 | Train Accuracy: 45.2000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.5153 | Train Accuracy: 46.5000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.5241 | Train Accuracy: 47.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.5406 | Train Accuracy: 48.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.5568 | Train Accuracy: 49.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.5760 | Train Accuracy: 50.4000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.5890 | Train Accuracy: 51.5000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.6039 | Train Accuracy: 52.3000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.6161 | Train Accuracy: 53.3000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.6278 | Train Accuracy: 54.5000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.6436 | Train Accuracy: 55.4000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.6571 | Train Accuracy: 56.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.6687 | Train Accuracy: 57.7000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.6826 | Train Accuracy: 58.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7026 | Train Accuracy: 59.6000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7107 | Train Accuracy: 60.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7290 | Train Accuracy: 61.8000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7386 | Train Accuracy: 63.1000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7561 | Train Accuracy: 64.1000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7643 | Train Accuracy: 65.3000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7732 | Train Accuracy: 66.4000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7886 | Train Accuracy: 67.2000%\n",
            "Epoch : 4 / 5\n",
            "Train Loss: 0.7978 | Train Accuracy: 67.9000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0097 | Train Accuracy: 1.2000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0189 | Train Accuracy: 2.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0250 | Train Accuracy: 4.0000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0417 | Train Accuracy: 5.1000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0527 | Train Accuracy: 6.1000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0683 | Train Accuracy: 7.0000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0791 | Train Accuracy: 8.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.0885 | Train Accuracy: 9.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1024 | Train Accuracy: 10.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1132 | Train Accuracy: 11.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1270 | Train Accuracy: 12.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1414 | Train Accuracy: 13.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1572 | Train Accuracy: 14.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1651 | Train Accuracy: 15.8000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1779 | Train Accuracy: 16.9000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.1888 | Train Accuracy: 18.2000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2024 | Train Accuracy: 19.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2168 | Train Accuracy: 20.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2260 | Train Accuracy: 21.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2411 | Train Accuracy: 22.7000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2615 | Train Accuracy: 23.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2752 | Train Accuracy: 24.4000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2861 | Train Accuracy: 25.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.2981 | Train Accuracy: 26.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.3080 | Train Accuracy: 27.9000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.3246 | Train Accuracy: 29.0000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.3423 | Train Accuracy: 29.9000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.3533 | Train Accuracy: 31.0000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.3629 | Train Accuracy: 32.2000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.3800 | Train Accuracy: 33.2000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.3908 | Train Accuracy: 34.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4003 | Train Accuracy: 35.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4133 | Train Accuracy: 36.7000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4289 | Train Accuracy: 37.7000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4424 | Train Accuracy: 38.8000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4553 | Train Accuracy: 39.9000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4685 | Train Accuracy: 41.0000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4765 | Train Accuracy: 42.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4873 | Train Accuracy: 43.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.4958 | Train Accuracy: 44.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.5141 | Train Accuracy: 45.4000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.5261 | Train Accuracy: 46.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.5404 | Train Accuracy: 47.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.5535 | Train Accuracy: 48.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.5669 | Train Accuracy: 49.7000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.5798 | Train Accuracy: 50.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.5939 | Train Accuracy: 51.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.6051 | Train Accuracy: 52.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.6154 | Train Accuracy: 53.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.6329 | Train Accuracy: 54.7000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.6476 | Train Accuracy: 55.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.6627 | Train Accuracy: 56.4000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.6727 | Train Accuracy: 57.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.6826 | Train Accuracy: 58.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7014 | Train Accuracy: 59.3000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7092 | Train Accuracy: 60.7000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7226 | Train Accuracy: 61.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7381 | Train Accuracy: 62.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7524 | Train Accuracy: 63.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7679 | Train Accuracy: 64.7000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7787 | Train Accuracy: 65.6000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.7901 | Train Accuracy: 66.5000%\n",
            "Epoch : 5 / 5\n",
            "Train Loss: 0.8008 | Train Accuracy: 67.0000%\n"
          ]
        }
      ],
      "source": [
        "# Fixing a random seed for reproducibility across different runs\n",
        "torch.manual_seed(100)\n",
        "\n",
        "# Defining the number of epochs\n",
        "epochs = 5\n",
        "\n",
        "# Detecting to see if the GPU is available and use it, otherwise use the CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# defining the learning rate\n",
        "learning_rate = 1\n",
        "\n",
        "# Configuring the optimizer for SGD using the model parameters and lr = 1\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# moving the model to the appropriate device (GPU or CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Apply custom weight initialization; this can affect the model's learning trajectory\n",
        "# The `apply` function recursively applies a function to each submodule in a PyTorch model.\n",
        "# In the given context, it's used to apply the `init_weights` function to initialize the weights of all layers in the model.\n",
        "# The benefit is that it provides a convenient way to systematically apply custom weight initialization across complex models,\n",
        "# potentially improving model convergence and performance.\n",
        "model.apply(init_weights)\n",
        "\n",
        "# Kicking of the training process using the specified settings\n",
        "train(epochs, loss_function, learning_rate, model, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed06d78",
      "metadata": {
        "id": "9ed06d78"
      },
      "source": [
        "### <font color='orange'>**Final model parameters**</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6adf34a",
      "metadata": {
        "id": "a6adf34a",
        "outputId": "355882a5-ff09-4744-df24-491dd64d5b92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weight tensor([[ 0.4345, -0.9407, -0.5891, -0.4591,  0.7364],\n",
            "        [ 0.0557,  1.0332,  0.1920,  0.4732,  0.0554],\n",
            "        [-0.6367, -0.0987,  0.2159,  0.0453, -0.8418]])\n",
            "bias tensor([-0.2508, -0.0254,  0.2762])\n"
          ]
        }
      ],
      "source": [
        "# Output the learned parameters (weights and biases) of the model after training\n",
        "for name, param in model.named_parameters():\n",
        "  # Print the name and the values of each parameter\n",
        "  print(name, param.data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b82ebe68",
      "metadata": {
        "id": "b82ebe68"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}